{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import config as cfg\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH ='data'\n",
    "PASCAL_PATH = os.path.join(DATA_PATH, 'pascal_voc')\n",
    "CACHE_PATH = os.path.join(PASCAL_PATH, 'cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pascal_voc(object):\n",
    "    def __init__(self, phase, rebuild=False):\n",
    "        self.devkil_path = os.path.join(PASCAL_PATH, 'VOCdevkit')\n",
    "        self.data_path = os.path.join(self.devkil_path, 'VOC2007')\n",
    "        self.cache_path = CACHE_PATH\n",
    "        self.batch_size = 20\n",
    "        self.image_size = 448\n",
    "        self.cell_size = 7\n",
    "        self.classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "           'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "           'train', 'tvmonitor']\n",
    "        self.class_to_ind = dict(zip(self.classes, range(len(self.classes)))) #create dict where keys = labels\n",
    "        self.flipped = True\n",
    "        self.phase = phase\n",
    "        self.rebuild = rebuild\n",
    "        self.cursor = 0\n",
    "        self.epoch = 1\n",
    "        self.labels_got = None\n",
    "        self.prepare()\n",
    "        \n",
    "    def get(self):\n",
    "        X_img = np.zeros((self.batch_size, self.image_size, self.image_size, 3))\n",
    "        Y_labels = np.zeros((self.batch_size, self.cell_size, self.cell_size, 25))\n",
    "        count_batch = 0\n",
    "        while count_batch < self.batch_size:\n",
    "            img_name = self.labels_got[self.cursor]['imname']\n",
    "            flipped = self.labels_got[self.cursor]['flipped']\n",
    "            X_img[count_batch, :,:,:] = self.read_image(img_name,flipped)\n",
    "            Y_labels[count_batch, :,:,:] = self.labels_got[self.cursor]['label']\n",
    "            count_batch +=1\n",
    "        \n",
    "        return X_img, Y_labels\n",
    "        \n",
    "            \n",
    "    def read_image(self, img_name, flipped=False):\n",
    "        image = cv2.imread(img_name)\n",
    "        # resize image to 448 , 448\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = (image /255.0) *2 -1.0\n",
    "        if flipped:\n",
    "            image = image[:,::-1,:]        \n",
    "        return image\n",
    "    \n",
    "    def prepare(self):\n",
    "        print(\"In prepare\")\n",
    "        # contains list of dict where each dicts where each dict contain file path, 3D labels & if flipped or not\n",
    "        labels_got = self.get_labels()\n",
    "        #print(labels_got[0:10])\n",
    "        #print(labels_got[0]['label'])\n",
    "        if self.flipped:\n",
    "            print('Appending horizontally-flipped training examples ...')\n",
    "            labels_copy = copy.deepcopy(labels_got)\n",
    "            added_labels = self.data_augment(labels_got,labels_copy)\n",
    "        np.random.shuffle(added_labels)\n",
    "        self.labels_got = added_labels\n",
    "        print(\"labels len\", len(added_labels))\n",
    "        return labels_got\n",
    "        \n",
    "    \n",
    "    def data_augment(self, orig_labels, labels_copy):\n",
    "        print(\"Create flipped data\")\n",
    "        for index in range(len(labels_copy)):\n",
    "            labels_copy[index]['flipped'] = True\n",
    "            labels_copy[index]['label'] = labels_copy[index]['label'][:,::-1,:]\n",
    "            \n",
    "            for i in range(self.cell_size):\n",
    "                for j in range(self.cell_size):\n",
    "                    if labels_copy[index]['label'][i,j,0] == 1:\n",
    "                        #print(labels_copy[index]['label'][i,j,2])\n",
    "                        labels_copy[index]['label'][i,j,1] = self.image_size-1-labels_copy[index]['label'][i,j,1]\n",
    "                        #print(labels_copy[index]['label'][i,j,2])\n",
    "        orig_labels+= labels_copy\n",
    "        return orig_labels\n",
    "        \n",
    "        \n",
    "    def get_labels(self):\n",
    "        # getting file containing data\n",
    "        cache_file = os.path.join(self.cache_path,'pascal_'+self.phase+'_gt_labels.pkl')\n",
    "        print(self.cache_path)\n",
    "        if(os.path.isfile(cache_file) and not self.rebuild):\n",
    "            print(\"Getting labels from \"+ cache_file)\n",
    "            with open(cache_file, 'rb') as labels_file:\n",
    "                labels_got = pickle.load(labels_file)\n",
    "                \n",
    "            print(\"original labels length :\", len(labels_got))\n",
    "            return labels_got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloNet(object):\n",
    "    \n",
    "    def __init__(self, is_training=True):\n",
    "        self.classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "           'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "           'train', 'tvmonitor']\n",
    "        self.num_of_classes = len(self.classes)\n",
    "        self.image_size = 448\n",
    "        self.cell_size = 7\n",
    "        self.boxes_per_cell = 2 \n",
    "        # output size = S*S * B*5 + Cls\n",
    "        self.output_size = (self.cell_size * self.cell_size) * (self.num_of_classes + self.boxes_per_cell * 5)\n",
    "        self.object_scale = 1.0\n",
    "        self.no_object_scale = 1.0\n",
    "        self.class_scale = 2.0\n",
    "        self.coordi_scale = 5.0\n",
    "        \n",
    "        self.learning_rate = 0.0001\n",
    "        self.batch_size = 20\n",
    "        self.alpha = 0.1\n",
    "        self.boundary1 = self.cell_size * self.cell_size * self.num_of_classes # 7*7*20 = 980\n",
    "        self.boundary2 = self.boundary1 +\\\n",
    "            self.cell_size * self.cell_size * self.boxes_per_cell # 980 + 7*7*2(98) = 1078\n",
    "\n",
    "        \n",
    "        #(7, 7, 2)\n",
    "        self.offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell),\n",
    "            (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))\n",
    "        self.images = tf.placeholder(\n",
    "            tf.float32, [None, self.image_size, self.image_size, 3],\n",
    "            name='images')\n",
    "        self.logits = self.build_network(self.images, num_outputs=self.output_size, alpha=self.alpha,is_training=True)\n",
    "        \n",
    "        if is_training:\n",
    "            self.labels = tf.placeholder(\n",
    "                tf.float32,\n",
    "                [None, self.cell_size, self.cell_size, 5 + self.num_of_classes])\n",
    "            self.loss_layer(self.logits, self.labels)\n",
    "            self.total_loss = tf.losses.get_total_loss()\n",
    "            tf.summary.scalar('total_loss', self.total_loss)\n",
    "\n",
    "    def build_network(self, images, num_outputs, alpha, keep_prob=0.5, is_training=True, scope='yolo'):\n",
    "        with tf.variable_scope(scope):\n",
    "            with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                activation_fn=leaky_relu(alpha),\n",
    "                weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                # truncated help in convergance\n",
    "                weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)\n",
    "            ):\n",
    "                net = tf.pad(images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]),name='pad_1')\n",
    "                #print(\"Start padd\", net)\n",
    "                # 64 filters of 7 *7 with stride of 2 padding = no padding\n",
    "                net = slim.conv2d(\n",
    "                    net, 64, 7, 2, padding='VALID', scope='conv_2')\n",
    "                #print(\"1st conv\", net)\n",
    "                # Max Pooling layer padding = same as input dimension. Stride = 2\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_3')\n",
    "                \n",
    "                net = slim.conv2d(net, 192, 3, scope='conv_4')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_5')\n",
    "                \n",
    "                net = slim.conv2d(net, 128, 1, scope='conv_6')\n",
    "                net = slim.conv2d(net, 256, 3, scope='conv_7')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_8')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_9')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_10')\n",
    "                \n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_11')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_12')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_13')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_14')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_15')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_16')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_17')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_18')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_19')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_20')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_21')\n",
    "                \n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_22')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_23')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_24')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_25')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_26')\n",
    "                net = tf.pad(net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]),name='pad_27')\n",
    "                net = slim.conv2d(\n",
    "                    net, 1024, 3, 2, padding='VALID', scope='conv_28')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_29')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_30')\n",
    "                # transpose to change NHWC([batch_size, height, width, channels]) to NCHW\n",
    "                net = tf.transpose(net, [0, 3, 1, 2], name='trans_31')\n",
    "                net = slim.flatten(net, scope='flat_32')\n",
    "                net = slim.fully_connected(net, 512, scope='fc_33')\n",
    "                #=4096\n",
    "                net = slim.fully_connected(net, 4096, scope='fc_34')\n",
    "                #print(net)\n",
    "                net = slim.dropout(\n",
    "                    net, keep_prob=keep_prob, is_training=True,\n",
    "                    scope='dropout_35')\n",
    "                #7 x 7 x (2 x 5 + 20) = 7 x 7 x 30 tensor  = 1470\n",
    "                net = slim.fully_connected(\n",
    "                    net, num_outputs, activation_fn=None, scope='fc_36')        \n",
    "                print(net)\n",
    "        return net\n",
    "\n",
    "    def calculate_iou(self, boxes1, boxes2, scope='iou'):\n",
    "        with tf.variable_scope(scope):\n",
    "            # covert (x_center,y_center,w,h) to (x1,y1,x2,y2)\n",
    "\n",
    "            boxes1_temp = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,  # x_c - w/2 => x_1\n",
    "                                 boxes1[..., 1] - boxes1[..., 3] / 2.0,  # y_c - h/2 => y_1\n",
    "                                 boxes1[..., 0] + boxes1[..., 2] / 2.0,  # x_c + w/2 => x_2\n",
    "                                 boxes1[..., 1] + boxes1[..., 3] / 2.0], # y_c + h/2 => y_2\n",
    "                                axis=-1)\n",
    "\n",
    "            boxes2_temp = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                                 boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                                axis=-1)\n",
    "            \n",
    "            lu = tf.maximum(boxes1_temp[...,:2],boxes2_temp[...,:2])\n",
    "            ru = tf.minimum(boxes1_temp[...,2:],boxes2_temp[...,2:])\n",
    "            \n",
    "            # intersection| calculating width and height of intersectioned regionregioni.e x2-x1, y2-y1\n",
    "            intersection = tf.maximum(0.0, lu-ru)\n",
    "            # calculate area of overlapped region by width*height\n",
    "            intersection_area = intersection[...,0] * intersection[...,1]\n",
    "            \n",
    "            box1_area = boxes1[...,2] * boxes1[...,3]\n",
    "            box2_area = boxes2[...,2] * boxes2[...,3]\n",
    "            \n",
    "            union = tf.maximum(box1_area + box2_area - intersection_area, 1e-10)\n",
    "            \n",
    "        return tf.clip_by_value(intersection_area / union, 0.0, 1.0)\n",
    "    \n",
    "    \n",
    "    def loss_layer(self, predicts, labels,  scope = \"loss_layer\"):\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            predict_classes = tf.reshape(predicts[:,:self.boundary1],\n",
    "                                        [self.batch_size, self.cell_size, self.cell_size, self.num_of_classes])\n",
    "            \n",
    "            predict_scales = tf.reshape(predicts[:,self.boundary1:self.boundary2],\n",
    "                                       [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            \n",
    "            predict_boxes = tf.reshape(predicts[:,self.boundary2:],\n",
    "                                      [self.batch_size, self.cell_size, self.cell_size,self.boxes_per_cell, 4])\n",
    "            \n",
    "            \n",
    "            classes = labels[...,5:]\n",
    "            \n",
    "            response = tf.reshape(labels[...,0],\n",
    "                                 [self.batch_size, self.cell_size, self.cell_size, 1])\n",
    "            \n",
    "            boxes = tf.reshape(labels[...,1:5],\n",
    "                              [self.batch_size, self.cell_size, self.cell_size, 1, 4])\n",
    "            \n",
    "            boxes = tf.tile(boxes, [1,1,1, self.boxes_per_cell, 1]) / self.image_size\n",
    "            \n",
    "            #shape=(1, 7, 7, 2)\n",
    "            offset = tf.reshape(\n",
    "                tf.constant(self.offset, dtype=tf.float32),\n",
    "                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            # Tile operation creates a new tensor by replicating input multiples times\n",
    "            # [[[0. 0.]\n",
    "            #   [1. 1.]  X 7) X 7\n",
    "            #   ...\n",
    "            #   [6. 6.]\n",
    "            # offest[0,:,:,1] =>1st row => [0. 1. 2. 3. 4. 5. 6.]\n",
    "            offset = tf.tile(offset, [self.batch_size, 1, 1, 1]) \n",
    "            \n",
    "            # [[[0. 0.]                  [[[1. 1.]                  \n",
    "            #   [0. 0.]  X 7) X 7          [1. 1.]\n",
    "            #   ...                        ...\n",
    "            #   [0. 0.]                    [1.  1.]\n",
    "            # offest[0,:,:,1] =>1st row => [0. 0. 0. 0. 0. 0. 0.]\n",
    "            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "            \n",
    "            # here sqaure is for calculating width and height of predicted bbox for IOU calculation\n",
    "            predict_boxes_tran = tf.stack(\n",
    "                [(predict_boxes[..., 0] + offset)/self.cell_size, # position of x_c within cell containing obj  \n",
    "                 (predict_boxes[..., 1] + offset_tran)/ self.cell_size,  # position of y_c within cell containing obj \n",
    "                 tf.square(predict_boxes[..., 2]),                        # take sqaure of (𝑤^1/2) => w\n",
    "                 tf.square(predict_boxes[..., 3])], axis=-1)              # take sqaure of (h^1/2) => h\n",
    "            \n",
    "            iou_predict_truth = self.calculate_iou(predict_boxes_tran, boxes)\n",
    "\n",
    "             # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "            object_mask = tf.cast(\n",
    "                (iou_predict_truth >= object_mask), tf.float32) * response\n",
    "\n",
    "            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            noobject_mask = tf.ones_like(\n",
    "                object_mask, dtype=tf.float32) - object_mask\n",
    "            # (7,7,4)\n",
    "            boxes_tran = tf.stack(\n",
    "                [boxes[..., 0] * self.cell_size - offset,\n",
    "                 boxes[..., 1] * self.cell_size - offset_tran,\n",
    "                 tf.sqrt(boxes[..., 2]),\n",
    "                 tf.sqrt(boxes[..., 3])], axis=-1)\n",
    "\n",
    "            # class_loss\n",
    "            # ∑𝑆2𝑖=0 * 𝟙i𝑜𝑏𝑗  * ∑𝑐∈𝑐𝑙𝑎𝑠𝑠𝑒𝑠(𝑝𝑖(𝑐)−𝑝̂ 𝑖(𝑐))2 | 𝟙i𝑜𝑏𝑗 is 1 when there is a particular class is predicted, else 0\n",
    "            class_delta = response * (predict_classes - classes)\n",
    "            class_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n",
    "                name='class_loss') * self.class_scale \n",
    "\n",
    "\n",
    "            # object_loss\n",
    "            # ∑𝑆^2𝑖=0 ∑Bj=0 𝟙𝑖𝑗𝑜𝑏𝑗 * (𝐶𝑖−𝐶̂ 𝑖)2 | 𝟙𝑖𝑗𝑜𝑏𝑗 \"denotes that the 𝑗th bounding box predictor in cell 𝑖 is responsible for that prediction\". \n",
    "            # In other words, it is equal to 1 if there is an object in cell 𝑖 and confidence of the 𝑗th predictors of this cell is the highest \n",
    "            # among all the predictors of this cell.\n",
    "            object_delta = object_mask * (predict_scales - iou_predict_truth) # object_mask = 1_ij\n",
    "            object_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n",
    "                name='object_loss') * self.object_scale # (obj_scale =1)\n",
    "\n",
    "\n",
    "            # noobject_loss\n",
    "            # 𝜆𝑛𝑜𝑜𝑏𝑗 * ∑𝑆2𝑖=0 ∑Bj=0 𝟙𝑖𝑗𝑛𝑜𝑜𝑏𝑗 * (𝐶𝑖−𝐶̂ 𝑖)2  | 𝟙𝑖𝑗𝑛𝑜𝑜𝑏𝑗 is almost the same except it values 1 when there are NO objects in cell 𝑖\n",
    "            #If there are no objects in cell, then truth confidence should be zero. so we get: noobject_delta = noobject_mask * (predict_scales - 0)\n",
    "            noobject_delta = noobject_mask * predict_scales # \n",
    "            noobject_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n",
    "                name='noobject_loss') * self.no_object_scale # (no_obj_scale =1)\n",
    "\n",
    "            # coord_loss\n",
    "            # 𝜆𝑐𝑜𝑜𝑟𝑑∑𝑆2𝑖=0[(𝑥𝑖−𝑥̂ 𝑖)2+(𝑦𝑖−𝑦𝑖^)2]+ 𝜆𝑐𝑜𝑜𝑟𝑑∑𝑆2𝑖=0[(𝑤𝑖‾‾‾√−𝑤̂ 𝑖‾‾‾√)2+(ℎ𝑖‾‾√−ℎ̂ 𝑖‾‾√)2]\n",
    "            coord_mask = tf.expand_dims(object_mask, 4)\n",
    "            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n",
    "            coord_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n",
    "                name='coord_loss') * self.coordi_scale # (coordi_scale = 5)\n",
    "            tf.losses.add_loss(class_loss)\n",
    "            tf.losses.add_loss(object_loss)\n",
    "            tf.losses.add_loss(noobject_loss)\n",
    "            tf.losses.add_loss(coord_loss)\n",
    "\n",
    "            tf.summary.scalar('class_loss', class_loss)\n",
    "            tf.summary.scalar('object_loss', object_loss)\n",
    "            tf.summary.scalar('noobject_loss', noobject_loss)\n",
    "            tf.summary.scalar('coord_loss', coord_loss)\n",
    "\n",
    "            tf.summary.histogram('boxes_delta_x', boxes_delta[..., 0])\n",
    "            tf.summary.histogram('boxes_delta_y', boxes_delta[..., 1])\n",
    "            tf.summary.histogram('boxes_delta_w', boxes_delta[..., 2])\n",
    "            tf.summary.histogram('boxes_delta_h', boxes_delta[..., 3])\n",
    "            tf.summary.histogram('iou', iou_predict_truth)\n",
    "\n",
    "            \n",
    "            \n",
    "def leaky_relu(alpha):\n",
    "    def op(inputs):\n",
    "        return tf.nn.leaky_relu(inputs, alpha=alpha, name='leaky_relu')\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo = YoloNet(is_training= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolotrain(object):\n",
    "\n",
    "    def __init__(self, net, data):\n",
    "        self.net = net\n",
    "        self.data = data\n",
    "        #self.weights_file = cfg.WEIGHTS_FILE\n",
    "        self.max_iter = cfg.MAX_ITER\n",
    "        self.initial_learning_rate = cfg.LEARNING_RATE\n",
    "        self.decay_steps = cfg.DECAY_STEPS\n",
    "        self.decay_rate = cfg.DECAY_RATE\n",
    "        self.staircase = cfg.STAIRCASE\n",
    "        self.summary_iter = cfg.SUMMARY_ITER\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        \n",
    "        self.global_step = tf.train.create_global_step()\n",
    "        self.learning_rate = tf.train.exponential_decay(\n",
    "            self.initial_learning_rate, self.global_step, self.decay_steps,\n",
    "            self.decay_rate, self.staircase, name='learning_rate')\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=self.learning_rate)\n",
    "        self.train_op = slim.learning.create_train_op(\n",
    "            self.net.total_loss, self.optimizer, global_step=self.global_step)\n",
    "      \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        #for step in range(1, self.max_iter + 1):\n",
    "        for step in range(1, 1 + 1):\n",
    "            images, labels = self.data.get()\n",
    "            feed_dict = {self.net.images: images,\n",
    "                         self.net.labels: labels}\n",
    "            print(\"Step\",step)\n",
    "            summary_str, loss, _ = self.sess.run(\n",
    "                [self.summary_op, self.net.total_loss, self.train_op],\n",
    "                feed_dict=feed_dict)\n",
    "            #print(summary_str)\n",
    "            print(\"loss :\",loss)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In prepare\n",
      "data/pascal_voc/cache\n",
      "Getting labels from data/pascal_voc/cache/pascal_train_gt_labels.pkl\n",
      "original labels length : 5011\n",
      "Appending horizontally-flipped training examples ...\n",
      "Create flipped data\n",
      "labels len 10022\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Tensor(\"yolo/fc_36/BiasAdd:0\", shape=(?, 1470), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-4-1400b5f9935a>:192: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Start training ...\n",
      "Step 1\n",
      "loss : 63.854614\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pascal_dataset = dataset_pascal_voc('train')\n",
    "yolo = YoloNet()\n",
    "train_yolo_obj = Yolotrain(yolo, pascal_dataset)\n",
    " \n",
    "\n",
    "print('Start training ...')\n",
    "train_yolo_obj.train()\n",
    "print('Done training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
