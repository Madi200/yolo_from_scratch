{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import config as cfg\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "#from __future__ import print_function\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH ='data'\n",
    "PASCAL_PATH = os.path.join(DATA_PATH, 'pascal_voc')\n",
    "CACHE_PATH = os.path.join(PASCAL_PATH, 'cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pascal_voc(object):\n",
    "    def __init__(self, phase, rebuild=False):\n",
    "        self.devkil_path = os.path.join(cfg.PASCAL_PATH, 'VOCdevkit')\n",
    "        self.data_path = os.path.join(self.devkil_path, 'VOC2007')\n",
    "        self.cache_path = cfg.CACHE_PATH\n",
    "        self.batch_size = cfg.BATCH_SIZE\n",
    "        self.image_size = cfg.IMAGE_SIZE\n",
    "        self.cell_size = cfg.CELL_SIZE\n",
    "        self.classes = cfg.CLASSES\n",
    "        self.class_to_ind = dict(zip(self.classes, range(len(self.classes)))) #create dict where keys = labels\n",
    "        self.flipped = True\n",
    "        self.phase = phase\n",
    "        self.rebuild = rebuild\n",
    "        self.cursor = 0\n",
    "        self.epoch = 1\n",
    "        self.labels_got = None\n",
    "        self.prepare()\n",
    "        \n",
    "    def get(self):\n",
    "        X_img = np.zeros((self.batch_size, self.image_size, self.image_size, 3))\n",
    "        Y_labels = np.zeros((self.batch_size, self.cell_size, self.cell_size, 25))\n",
    "        count_batch = 0\n",
    "        while count_batch < self.batch_size:\n",
    "            img_name = self.labels_got[self.cursor]['imname']\n",
    "            flipped = self.labels_got[self.cursor]['flipped']\n",
    "            X_img[count_batch, :,:,:] = self.read_image(img_name,flipped)\n",
    "            Y_labels[count_batch, :,:,:] = self.labels_got[self.cursor]['label']\n",
    "            count_batch +=1\n",
    "        \n",
    "        return X_img, Y_labels\n",
    "        \n",
    "            \n",
    "    def read_image(self, img_name, flipped=False):\n",
    "        image = cv2.imread(img_name)\n",
    "        # resize image to 448 , 448\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image = (image /255.0) *2 -1.0\n",
    "        if flipped:\n",
    "            image = image[:,::-1,:]        \n",
    "        return image\n",
    "    \n",
    "    def prepare(self):\n",
    "        print(\"In prepare\")\n",
    "        # contains list of dict where each dicts where each dict contain file path, 3D labels & if flipped or not\n",
    "        labels_got = self.get_labels()\n",
    "        #print(labels_got[0:10])\n",
    "        #print(labels_got[0]['label'])\n",
    "        if self.flipped:\n",
    "            print('Appending horizontally-flipped training examples ...')\n",
    "            labels_copy = copy.deepcopy(labels_got)\n",
    "            added_labels = self.data_augment(labels_got,labels_copy)\n",
    "        np.random.shuffle(added_labels)\n",
    "        self.labels_got = added_labels\n",
    "        print(\"labels len\", len(added_labels))\n",
    "        return labels_got\n",
    "        \n",
    "    \n",
    "    def data_augment(self, orig_labels, labels_copy):\n",
    "        print(\"Create flipped data\")\n",
    "        for index in range(len(labels_copy)):\n",
    "            labels_copy[index]['flipped'] = True\n",
    "            labels_copy[index]['label'] = labels_copy[index]['label'][:,::-1,:]\n",
    "            \n",
    "            for i in range(self.cell_size):\n",
    "                for j in range(self.cell_size):\n",
    "                    if labels_copy[index]['label'][i,j,0] == 1:\n",
    "                        #print(labels_copy[index]['label'][i,j,2])\n",
    "                        labels_copy[index]['label'][i,j,1] = self.image_size-1-labels_copy[index]['label'][i,j,1]\n",
    "                        #print(labels_copy[index]['label'][i,j,2])\n",
    "        orig_labels+= labels_copy\n",
    "        return orig_labels\n",
    "        \n",
    "        \n",
    "    def get_labels(self):\n",
    "        # getting file containing data\n",
    "        cache_file = os.path.join(self.cache_path,'pascal_'+self.phase+'_gt_labels.pkl')\n",
    "        print(self.cache_path)\n",
    "        if(os.path.isfile(cache_file) and not self.rebuild):\n",
    "            print(\"Getting labels from \"+ cache_file)\n",
    "            with open(cache_file, 'rb') as labels_file:\n",
    "                labels_got = pickle.load(labels_file)\n",
    "                \n",
    "            print(\"original labels length :\", len(labels_got))\n",
    "            return labels_got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloNet(object):\n",
    "    \n",
    "    def __init__(self, is_training=True):\n",
    "        self.classes = cfg.CLASSES\n",
    "        self.num_of_classes = len(self.classes)\n",
    "        self.image_size = cfg.IMAGE_SIZE\n",
    "        self.cell_size = cfg.CELL_SIZE\n",
    "        self.boxes_per_cell = cfg.BOXES_PER_CELL\n",
    "        # output size = S*S * B*5 + Cls\n",
    "        self.output_size = (self.cell_size * self.cell_size) * (self.num_of_classes + self.boxes_per_cell * 5)\n",
    "        #self.predict_boxes_print = self.placeholder(tf.float32, [20, 7, 7, 2, 4])\n",
    "        self.object_scale = cfg.OBJECT_SCALE\n",
    "        self.no_object_scale = cfg.NOOBJECT_SCALE\n",
    "        self.class_scale = cfg.CLASS_SCALE\n",
    "        self.coordi_scale = cfg.COORD_SCALE\n",
    "        \n",
    "        self.learning_rate = cfg.LEARNING_RATE\n",
    "        self.batch_size = cfg.BATCH_SIZE\n",
    "        self.alpha = cfg.ALPHA\n",
    "        self.boundary1 = self.cell_size * self.cell_size * self.num_of_classes # 7*7*20 = 980\n",
    "        self.boundary2 = self.boundary1 +\\\n",
    "            self.cell_size * self.cell_size * self.boxes_per_cell # 980 + 7*7*2(98) = 1078\n",
    "\n",
    "        \n",
    "        #(7, 7, 2)\n",
    "        self.offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell),\n",
    "            (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))\n",
    "        self.images = tf.placeholder(\n",
    "            tf.float32, [None, self.image_size, self.image_size, 3],\n",
    "            name='images')\n",
    "        self.logits = self.build_network(self.images, num_outputs=self.output_size, alpha=self.alpha,is_training=True)\n",
    "        \n",
    "        if is_training:\n",
    "            self.labels = tf.placeholder(\n",
    "                tf.float32,\n",
    "                [None, self.cell_size, self.cell_size, 5 + self.num_of_classes])\n",
    "            self.loss_layer(self.logits, self.labels)\n",
    "            self.total_loss = tf.losses.get_total_loss()\n",
    "            tf.summary.scalar('total_loss', self.total_loss)\n",
    "\n",
    "    def build_network(self, images, num_outputs, alpha, keep_prob=0.5, is_training=True, scope='yolo'):\n",
    "        with tf.variable_scope(scope):\n",
    "            with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                activation_fn=leaky_relu(alpha),\n",
    "                weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                # truncated help in convergance\n",
    "                weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)\n",
    "            ):\n",
    "                net = tf.pad(images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]),name='pad_1')\n",
    "                #print(\"Start padd\", net)\n",
    "                # 64 filters of 7 *7 with stride of 2 padding = no padding\n",
    "                net = slim.conv2d(\n",
    "                    net, 64, 7, 2, padding='VALID', scope='conv_2')\n",
    "                #print(\"1st conv\", net)\n",
    "                # Max Pooling layer padding = same as input dimension. Stride = 2\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_3')\n",
    "                \n",
    "                net = slim.conv2d(net, 192, 3, scope='conv_4')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_5')\n",
    "                \n",
    "                net = slim.conv2d(net, 128, 1, scope='conv_6')\n",
    "                net = slim.conv2d(net, 256, 3, scope='conv_7')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_8')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_9')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_10')\n",
    "                \n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_11')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_12')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_13')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_14')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_15')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_16')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_17')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_18')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_19')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_20')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_21')\n",
    "                \n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_22')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_23')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_24')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_25')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_26')\n",
    "                net = tf.pad(net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]),name='pad_27')\n",
    "                net = slim.conv2d(\n",
    "                    net, 1024, 3, 2, padding='VALID', scope='conv_28')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_29')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_30')\n",
    "                # transpose to change NHWC([batch_size, height, width, channels]) to NCHW\n",
    "                net = tf.transpose(net, [0, 3, 1, 2], name='trans_31')\n",
    "                net = slim.flatten(net, scope='flat_32')\n",
    "                net = slim.fully_connected(net, 512, scope='fc_33')\n",
    "                #=4096\n",
    "                net = slim.fully_connected(net, 4096, scope='fc_34')\n",
    "                #print(net)\n",
    "                net = slim.dropout(\n",
    "                    net, keep_prob=1-keep_prob, is_training=True,\n",
    "                    scope='dropout_35')\n",
    "                #7 x 7 x (2 x 5 + 20) = 7 x 7 x 30 tensor  = 1470\n",
    "                net = slim.fully_connected(\n",
    "                    net, num_outputs, activation_fn=None, scope='fc_36')        \n",
    "                print(net)\n",
    "        return net\n",
    "\n",
    "    def calculate_iou(self, boxes1, boxes2, scope='iou'):\n",
    "        with tf.variable_scope(scope):\n",
    "            # covert (x_center,y_center,w,h) to (x1,y1,x2,y2)\n",
    "\n",
    "            boxes1_temp = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,  # x_c - w/2 => x_1\n",
    "                                 boxes1[..., 1] - boxes1[..., 3] / 2.0,  # y_c - h/2 => y_1\n",
    "                                 boxes1[..., 0] + boxes1[..., 2] / 2.0,  # x_c + w/2 => x_2\n",
    "                                 boxes1[..., 1] + boxes1[..., 3] / 2.0], # y_c + h/2 => y_2\n",
    "                                axis=-1)\n",
    "\n",
    "            boxes2_temp = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                                 boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                                axis=-1)\n",
    "            \n",
    "            lu = tf.maximum(boxes1_temp[...,:2],boxes2_temp[...,:2])\n",
    "            ru = tf.minimum(boxes1_temp[...,2:],boxes2_temp[...,2:])\n",
    "            \n",
    "            # intersection| calculating width and height of intersectioned regionregioni.e x2-x1, y2-y1\n",
    "            intersection = tf.maximum(0.0, lu-ru)\n",
    "            # calculate area of overlapped region by width*height\n",
    "            intersection_area = intersection[...,0] * intersection[...,1]\n",
    "            \n",
    "            box1_area = boxes1[...,2] * boxes1[...,3]\n",
    "            box2_area = boxes2[...,2] * boxes2[...,3]\n",
    "            \n",
    "            union = tf.maximum(box1_area + box2_area - intersection_area, 1e-10)\n",
    "            \n",
    "        return tf.clip_by_value(intersection_area / union, 0.0, 1.0) # value <0 : value =0 | value>1: value=1\n",
    "    \n",
    "    \n",
    "    def loss_layer(self, predicts, labels,  scope = \"loss_layer\"):\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            predict_classes = tf.reshape(predicts[:,:self.boundary1],\n",
    "                                        [self.batch_size, self.cell_size, self.cell_size, self.num_of_classes])\n",
    "            \n",
    "            predict_scales = tf.reshape(predicts[:,self.boundary1:self.boundary2],\n",
    "                                       [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            \n",
    "            predict_boxes = tf.reshape(predicts[:,self.boundary2:],\n",
    "                                      [self.batch_size, self.cell_size, self.cell_size,self.boxes_per_cell, 4])\n",
    "            \n",
    "            \n",
    "            classes = labels[...,5:]\n",
    "            \n",
    "            response = tf.reshape(labels[...,0],\n",
    "                                 [self.batch_size, self.cell_size, self.cell_size, 1])\n",
    "            \n",
    "            boxes = tf.reshape(labels[...,1:5],\n",
    "                              [self.batch_size, self.cell_size, self.cell_size, 1, 4])\n",
    "            \n",
    "            boxes = tf.tile(boxes, [1,1,1, self.boxes_per_cell, 1]) / self.image_size\n",
    "            \n",
    "            #shape=(1, 7, 7, 2)\n",
    "            offset = tf.reshape(\n",
    "                tf.constant(self.offset, dtype=tf.float32),\n",
    "                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            # Tile operation creates a new tensor by replicating input multiples times\n",
    "            # [[[0. 0.]\n",
    "            #   [1. 1.]  X 7) X 7\n",
    "            #   ...\n",
    "            #   [6. 6.]\n",
    "            # offest[0,:,:,1] =>1st row => [0. 1. 2. 3. 4. 5. 6.]\n",
    "            offset = tf.tile(offset, [self.batch_size, 1, 1, 1]) \n",
    "            \n",
    "            # [[[0. 0.]                  [[[1. 1.]                  \n",
    "            #   [0. 0.]  X 7) X 7          [1. 1.]\n",
    "            #   ...                        ...\n",
    "            #   [0. 0.]                    [1.  1.]\n",
    "            # offest[0,:,:,1] =>1st row => [0. 0. 0. 0. 0. 0. 0.]\n",
    "            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "            \n",
    "            # here sqaure is for calculating width and height of predicted bbox for IOU calculation\n",
    "            \n",
    "            predict_boxes_tran = tf.stack(\n",
    "                [(predict_boxes[..., 0] + offset)/self.cell_size, # position of x_c within cell containing obj   \n",
    "                 (predict_boxes[..., 1] + offset_tran)/ self.cell_size,  # position of y_c within cell containing obj \n",
    "                 tf.square(predict_boxes[..., 2]),                        # take sqaure of (ð‘¤^1/2) => w\n",
    "                 tf.square(predict_boxes[..., 3])], axis=-1)              # take sqaure of (h^1/2) => h\n",
    "            \n",
    "            #self.predict_boxes_print = predict_boxes_tran\n",
    "            #print_classes = tf.Print(self.predict_boxes_print,[self.predict_boxes_print],\"predict\")\n",
    "            \n",
    "            #tf.print(predict_boxes_tran,[predict_boxes_tran],\"predicted\")\n",
    "            \n",
    "            iou_predict_truth = self.calculate_iou(predict_boxes_tran, boxes)\n",
    "\n",
    "             # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "            object_mask = tf.cast(\n",
    "                (iou_predict_truth >= object_mask), tf.float32) * response\n",
    "#             # get the box\n",
    "#             object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "#             object_mask = tf.cast(\n",
    "#                 (iou_predict_truth >= object_mask), tf.float32) * response\n",
    "\n",
    "            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            \n",
    "            noobject_mask = tf.ones_like(\n",
    "                object_mask, dtype=tf.float32) - object_mask\n",
    "            # (7,7,4)\n",
    "            boxes_tran = tf.stack(\n",
    "                [boxes[..., 0] * self.cell_size - offset,\n",
    "                 boxes[..., 1] * self.cell_size - offset_tran,\n",
    "                 tf.sqrt(boxes[..., 2]),\n",
    "                 tf.sqrt(boxes[..., 3])], axis=-1)\n",
    "\n",
    "            # class_loss\n",
    "            # âˆ‘ð‘†2ð‘–=0 * ðŸ™ið‘œð‘ð‘—  * âˆ‘ð‘âˆˆð‘ð‘™ð‘Žð‘ ð‘ ð‘’ð‘ (ð‘ð‘–(ð‘)âˆ’ð‘Ì‚ ð‘–(ð‘))2 | ðŸ™ið‘œð‘ð‘— is 1 when there is a particular class is predicted, else 0\n",
    "            class_delta = response * (predict_classes - classes)\n",
    "            class_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n",
    "                name='class_loss') * self.class_scale \n",
    "\n",
    "\n",
    "            # object_loss\n",
    "            # âˆ‘ð‘†^2ð‘–=0 âˆ‘Bj=0 ðŸ™ð‘–ð‘—ð‘œð‘ð‘— * (ð¶ð‘–âˆ’ð¶Ì‚ ð‘–)2 | ðŸ™ð‘–ð‘—ð‘œð‘ð‘— \"denotes that the ð‘—th bounding box predictor in cell ð‘– is responsible for that prediction\". \n",
    "            # In other words, it is equal to 1 if there is an object in cell ð‘– and confidence of the ð‘—th predictors of this cell is the highest \n",
    "            # among all the predictors of this cell.\n",
    "            object_delta = object_mask * (predict_scales - iou_predict_truth) # object_mask = 1_ij\n",
    "            object_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n",
    "                name='object_loss') * self.object_scale # (obj_scale =1)\n",
    "\n",
    "\n",
    "            # noobject_loss\n",
    "            # ðœ†ð‘›ð‘œð‘œð‘ð‘— * âˆ‘ð‘†2ð‘–=0 âˆ‘Bj=0 ðŸ™ð‘–ð‘—ð‘›ð‘œð‘œð‘ð‘— * (ð¶ð‘–âˆ’ð¶Ì‚ ð‘–)2  | ðŸ™ð‘–ð‘—ð‘›ð‘œð‘œð‘ð‘— is almost the same except it values 1 when there are NO objects in cell ð‘–\n",
    "            #If there are no objects in cell, then truth confidence should be zero. so we get: noobject_delta = noobject_mask * (predict_scales - 0)\n",
    "            noobject_delta = noobject_mask * predict_scales # \n",
    "            noobject_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n",
    "                name='noobject_loss') * self.no_object_scale # (no_obj_scale =1)\n",
    "\n",
    "            # coord_loss\n",
    "            # ðœ†ð‘ð‘œð‘œð‘Ÿð‘‘âˆ‘ð‘†2ð‘–=0[(ð‘¥ð‘–âˆ’ð‘¥Ì‚ ð‘–)2+(ð‘¦ð‘–âˆ’ð‘¦ð‘–^)2]+ ðœ†ð‘ð‘œð‘œð‘Ÿð‘‘âˆ‘ð‘†2ð‘–=0[(ð‘¤ð‘–â€¾â€¾â€¾âˆšâˆ’ð‘¤Ì‚ ð‘–â€¾â€¾â€¾âˆš)2+(â„Žð‘–â€¾â€¾âˆšâˆ’â„ŽÌ‚ ð‘–â€¾â€¾âˆš)2]\n",
    "            coord_mask = tf.expand_dims(object_mask, 4)\n",
    "            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n",
    "            coord_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n",
    "                name='coord_loss') * self.coordi_scale # (coordi_scale = 5)\n",
    "            \n",
    "            \n",
    "            tf.losses.add_loss(class_loss)\n",
    "            tf.losses.add_loss(object_loss)\n",
    "            tf.losses.add_loss(noobject_loss)\n",
    "            tf.losses.add_loss(coord_loss)\n",
    "\n",
    "            tf.summary.scalar('class_loss', class_loss)\n",
    "            tf.summary.scalar('object_loss', object_loss)\n",
    "            tf.summary.scalar('noobject_loss', noobject_loss)\n",
    "            tf.summary.scalar('coord_loss', coord_loss)\n",
    "\n",
    "            tf.summary.histogram('boxes_delta_x', boxes_delta[..., 0])\n",
    "            tf.summary.histogram('boxes_delta_y', boxes_delta[..., 1])\n",
    "            tf.summary.histogram('boxes_delta_w', boxes_delta[..., 2])\n",
    "            tf.summary.histogram('boxes_delta_h', boxes_delta[..., 3])\n",
    "            tf.summary.histogram('iou', iou_predict_truth)\n",
    "\n",
    "            \n",
    "            \n",
    "def leaky_relu(alpha):\n",
    "    def op(inputs):\n",
    "        return tf.nn.leaky_relu(inputs, alpha=alpha, name='leaky_relu')\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_inputfn(data):\n",
    "    tensor_vval = tf.constant(data)\n",
    "    tensor_xray = tf.Print(tensor_vval, [tensor_vval], \"vvvvvvvvvvvvvvvvalue\")\n",
    "    return tensor_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainYolo(object):\n",
    "\n",
    "    def __init__(self, net, data):\n",
    "        self.net = net\n",
    "        self.data = data\n",
    "        self.weights_file = cfg.WEIGHTS_FILE\n",
    "        self.max_iter = cfg.MAX_ITER\n",
    "        self.initial_learning_rate = cfg.LEARNING_RATE\n",
    "        self.decay_steps = cfg.DECAY_STEPS\n",
    "        self.decay_rate = cfg.DECAY_RATE\n",
    "        self.staircase = cfg.STAIRCASE\n",
    "        self.summary_iter = cfg.SUMMARY_ITER\n",
    "        self.save_iter = cfg.SAVE_ITER\n",
    "        self.output_dir = os.path.join(\n",
    "            cfg.OUTPUT_DIR, datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "        self.save_cfg()\n",
    "\n",
    "        self.variable_to_restore = tf.global_variables()\n",
    "        self.saver = tf.train.Saver(self.variable_to_restore, max_to_keep=None)\n",
    "        self.ckpt_file = os.path.join(self.output_dir, 'yolo')\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.writer = tf.summary.FileWriter(self.output_dir, flush_secs=60)\n",
    "\n",
    "        self.global_step = tf.train.create_global_step()\n",
    "        self.learning_rate = tf.train.exponential_decay(\n",
    "            self.initial_learning_rate, self.global_step, self.decay_steps,\n",
    "            self.decay_rate, self.staircase, name='learning_rate')\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=self.learning_rate)\n",
    "        self.train_op = slim.learning.create_train_op(\n",
    "            self.net.total_loss, self.optimizer, global_step=self.global_step)\n",
    "\n",
    "        gpu_options = tf.GPUOptions()\n",
    "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if self.weights_file is not None:\n",
    "            print('Restoring weights from: ' + self.weights_file)\n",
    "            self.saver.restore(self.sess, self.weights_file)\n",
    "\n",
    "        self.writer.add_graph(self.sess.graph)\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "\n",
    "        for step in range(1, self.max_iter + 1):\n",
    "            print('step',step)\n",
    "\n",
    "            images, labels = self.data.get()\n",
    "            feed_dict = {self.net.images: images,\n",
    "                         self.net.labels: labels}\n",
    "\n",
    "            if step % self.summary_iter == 0:\n",
    "                if step % (self.summary_iter * 10) == 0:\n",
    "                    print(\"within if\")\n",
    "\n",
    "                    summary_str, loss, _ = self.sess.run(\n",
    "                        [self.summary_op, self.net.total_loss, self.train_op],\n",
    "                        feed_dict=feed_dict)\n",
    "\n",
    "                    log_str = '''Date:{}, Epoch: {}, Step: {}, Learning rate: {},'''\n",
    "                    ''' Loss: {:5.3f}\\n'''.format(\n",
    "                        datetime.datetime.now().strftime('%m-%d %H:%M:%S'),\n",
    "                        self.data.epoch,\n",
    "                        int(step),\n",
    "                        round(self.learning_rate.eval(session=self.sess), 6),\n",
    "                        loss)\n",
    "                    print(log_str)\n",
    "\n",
    "                else:\n",
    "                    print(\"1st else\")\n",
    "                    summary_str, _ = self.sess.run(\n",
    "                        [self.summary_op, self.train_op],\n",
    "                        feed_dict=feed_dict)\n",
    "\n",
    "                self.writer.add_summary(summary_str, step)\n",
    "\n",
    "            else:\n",
    "                print(\"2nd else\")\n",
    "                self.sess.run(self.train_op, feed_dict=feed_dict)\n",
    "\n",
    "                # save model weights when step % save_iter ==0\n",
    "            if step % self.save_iter == 0:\n",
    "                print('{} Saving checkpoint file to: {}'.format(\n",
    "                    datetime.datetime.now().strftime('%m-%d %H:%M:%S'),\n",
    "                    self.output_dir))\n",
    "                self.saver.save(\n",
    "                    self.sess, self.ckpt_file, global_step=self.global_step)\n",
    "\n",
    "    def save_cfg(self):\n",
    "\n",
    "        with open(os.path.join(self.output_dir, 'config.txt'), 'w') as f:\n",
    "            cfg_dict = cfg.__dict__\n",
    "            for key in sorted(cfg_dict.keys()):\n",
    "                if key[0].isupper():\n",
    "                    cfg_str = '{}: {}\\n'.format(key, cfg_dict[key])\n",
    "                    f.write(cfg_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg.GPU\n",
    "\n",
    "pascal_dataset = dataset_pascal_voc('train')\n",
    "yolo = YoloNet()\n",
    "train_yolo_obj = TrainYolo(yolo, pascal_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Start training ...')\n",
    "train_yolo_obj.train()\n",
    "print('Done training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 100\n",
    "\n",
    "SUMMARY_ITER = 5\n",
    "\n",
    "SAVE_ITER = 10\n",
    "for step in range(1, MAX_ITER + 1):\n",
    "        print('step',step)\n",
    "\n",
    "        if step % SUMMARY_ITER == 0:\n",
    "            if step % (SUMMARY_ITER * 10) == 0:\n",
    "                print(\"within 2nd if\")\n",
    "\n",
    "            else:\n",
    "                print(\"1st else\")\n",
    "\n",
    "        else:\n",
    "            print(\"2nd else\")\n",
    "\n",
    "        if step % SAVE_ITER== 0:\n",
    "            print(\"3rd if\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.path.realpath('yolo-2.meta'))\n",
    "print(os.path.abspath(\"yolo-2.meta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('/home/hawk_pc/yolo_from_scratch/data/pascal_voc/output/2019_06_14_02_02/yolo-2.meta')\n",
    "saver.restore(sess, '/home/hawk_pc/yolo_from_scratch/data/pascal_voc/output/2019_06_14_02_02/yolo-2')\n",
    "#graph = sess.graph\n",
    "# for node in graph.as_graph_def().node:\n",
    "#     if \"fc_36\" in node.name:\n",
    "#         print(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess,tf.train.latest_checkpoint(\"2019_06_14_02_02\")) \n",
    "#saver = tf.train.import_meta_graph(\"/home/hawk_pc/yolo_from_scratch/data/pascal_voc/output/2019_06_14_02_02/yolo-2.meta\")\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, meta_path+\"/data/pascal_voc/output/2019_06_14_02_02/checkpoint\")\n",
    "graph = sess.graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(object):\n",
    "\n",
    "    def __init__(self, net, weight_file):\n",
    "        self.net = net\n",
    "        self.weights_file = weight_file\n",
    "\n",
    "        self.classes = cfg.CLASSES\n",
    "        self.num_class = len(self.classes)\n",
    "        self.image_size = cfg.IMAGE_SIZE\n",
    "        self.cell_size = cfg.CELL_SIZE\n",
    "        self.boxes_per_cell = cfg.BOXES_PER_CELL\n",
    "        self.threshold = cfg.THRESHOLD\n",
    "        self.iou_threshold = cfg.IOU_THRESHOLD\n",
    "        self.boundary1 = self.cell_size * self.cell_size * self.num_class\n",
    "        self.boundary2 = self.boundary1 +\\\n",
    "            self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print('Restoring weights from: ' + self.weights_file)\n",
    "        #self.saver = tf.train.import_meta_graph('/home/hawk_pc/yolo_from_scratch/data/pascal_voc/output/2019_06_14_02_02/yolo-2.meta')\n",
    "        #self.saver.restore(self.sess, '/home/hawk_pc/yolo_from_scratch/data/pascal_voc/output/2019_06_14_02_02/yolo-2')\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.saver.restore(self.sess, self.weights_file)\n",
    "\n",
    "\n",
    "    def detect(self, img):\n",
    "        img_h, img_w, _ = img.shape\n",
    "        inputs = cv2.resize(img, (self.image_size, self.image_size))\n",
    "        inputs = cv2.cvtColor(inputs, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        inputs = (inputs / 255.0) * 2.0 - 1.0\n",
    "        inputs = np.reshape(inputs, (1, self.image_size, self.image_size, 3))\n",
    "        print(\"Input shape\",inputs.shape)\n",
    "\n",
    "        self.look_only_once(inputs)\n",
    "\n",
    "\n",
    "    def look_only_once(self, inputs):\n",
    "        # (1,1470)\n",
    "        net_output = self.sess.run(self.net.logits,\n",
    "                                   feed_dict={self.net.images: inputs})\n",
    "        \n",
    "        print(\"Net Output shape :\", net_output.shape)\n",
    "        print(\"Net Output Value :\", net_output)\n",
    "\n",
    " \n",
    "    def image_detector(self, imname, wait=0):\n",
    "        image = cv2.imread(imname)\n",
    "\n",
    "        self.detect(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [4, 5], [8, 9]])\n",
    "filter_mat_test = np.array(a >= 3, dtype='bool')\n",
    "print(filter_mat_test)\n",
    "filter_mat_boxes_test = np.nonzero(filter_mat_test)\n",
    "print(a[filter_mat_boxes_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Tensor(\"yolo/fc_36/BiasAdd:0\", shape=(?, 1470), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "yolo = YoloNet(False)\n",
    "weight_file = cfg.WEIGHTS_FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring weights from: data/weights/YOLO_small.ckpt\n",
      "WARNING:tensorflow:From /home/hawk_pc/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from data/weights/YOLO_small.ckpt\n",
      "Input shape (1, 448, 448, 3)\n",
      "Net Output shape : (1, 1470)\n",
      "Net Output Value : [[0.447892   0.02232639 0.0464194  ... 0.46708572 0.32219887 0.28959635]]\n",
      "range(0, 1)\n",
      "Scales... [[ 1.9242056e-05  4.3281508e-03  9.1489498e-04  7.8444388e-03\n",
      "   9.2050550e-04  2.9578642e-03  2.5506269e-03]\n",
      " [ 3.1755036e-03  5.9064664e-03  1.3049910e-02  9.0718316e-04\n",
      "  -2.1513016e-03  2.1220699e-03  5.0066668e-03]\n",
      " [-1.9240798e-03  2.3736809e-03 -9.6800327e-03 -4.8317863e-03\n",
      "  -2.7239621e-02  2.9419707e-03  3.4683871e-03]\n",
      " [-5.2653216e-03 -3.2920182e-02 -2.4007775e-02  3.8994023e-01\n",
      "   3.0162860e-02 -6.8838941e-04 -9.0657698e-04]\n",
      " [ 8.2501676e-03  7.2493879e-03  4.3935932e-02 -2.3313984e-02\n",
      "  -3.0640556e-02 -8.1528391e-04 -8.3611365e-03]\n",
      " [-3.7863616e-02 -1.0677131e-02 -4.1858880e-03  6.6747367e-03\n",
      "  -2.2985252e-02 -5.7927221e-03 -1.6774894e-03]\n",
      " [-6.6883471e-03  9.7029668e-04 -9.2140923e-04  3.8279220e-03\n",
      "   1.5858380e-02  6.1267903e-03  8.3064260e-03]]\n",
      "(7, 7, 2)\n",
      "[[[0.19713828 0.6097085 ]\n",
      "  [1.5607836  1.4380152 ]\n",
      "  [2.437407   2.4885533 ]\n",
      "  [3.4668155  3.4557004 ]\n",
      "  [4.4831133  4.426342  ]\n",
      "  [5.32539    5.5450077 ]\n",
      "  [6.3376203  6.6465306 ]]\n",
      "\n",
      " [[0.6844725  0.20156077]\n",
      "  [1.2736275  1.5443077 ]\n",
      "  [2.2747571  2.605896  ]\n",
      "  [3.5834107  3.3311148 ]\n",
      "  [4.435998   4.2930126 ]\n",
      "  [5.497355   5.2117305 ]\n",
      "  [6.35238    6.7279854 ]]\n",
      "\n",
      " [[0.7012626  0.18456042]\n",
      "  [1.5216806  1.328145  ]\n",
      "  [2.472948   2.5646427 ]\n",
      "  [3.7230852  3.5687659 ]\n",
      "  [4.405907   4.282235  ]\n",
      "  [5.5834947  5.3295126 ]\n",
      "  [6.4089823  6.716932  ]]\n",
      "\n",
      " [[0.1896207  0.6528523 ]\n",
      "  [1.3865992  1.5772405 ]\n",
      "  [2.5281081  2.3878467 ]\n",
      "  [3.7494705  3.9490407 ]\n",
      "  [4.128165   4.321983  ]\n",
      "  [5.4142613  5.4098673 ]\n",
      "  [6.4600253  6.7887115 ]]\n",
      "\n",
      " [[0.16650319 0.6276444 ]\n",
      "  [1.5996459  1.3003722 ]\n",
      "  [2.487269   2.3351307 ]\n",
      "  [3.55974    3.7536356 ]\n",
      "  [4.3305144  4.404652  ]\n",
      "  [5.5692573  5.437003  ]\n",
      "  [6.803853   6.411618  ]]\n",
      "\n",
      " [[0.19262384 0.6209536 ]\n",
      "  [1.6030563  1.2534729 ]\n",
      "  [2.508326   2.3802629 ]\n",
      "  [3.442524   3.6045494 ]\n",
      "  [4.430459   4.3673043 ]\n",
      "  [5.2499957  5.523517  ]\n",
      "  [6.7277985  6.382446  ]]\n",
      "\n",
      " [[0.21661785 0.6367641 ]\n",
      "  [1.4946837  1.1591237 ]\n",
      "  [2.5654292  2.2490141 ]\n",
      "  [3.291178   3.480278  ]\n",
      "  [4.224554   4.5409746 ]\n",
      "  [5.1849318  5.4490657 ]\n",
      "  [6.539948   6.4598937 ]]]\n",
      "******************************\n",
      "[[[0.50816494 0.4100275 ]\n",
      "  [0.5735745  0.19262818]\n",
      "  [0.17740577 0.518479  ]\n",
      "  [0.5929644  0.21400763]\n",
      "  [0.49505383 0.15495552]\n",
      "  [0.17673855 0.5251042 ]\n",
      "  [0.5331117  0.4608101 ]]\n",
      "\n",
      " [[0.5318485  0.52137756]\n",
      "  [0.4199201  0.5733968 ]\n",
      "  [0.5302827  0.5769276 ]\n",
      "  [0.5942631  0.47779334]\n",
      "  [0.5454223  0.5203801 ]\n",
      "  [0.49355942 0.40387407]\n",
      "  [0.43155408 0.5524013 ]]\n",
      "\n",
      " [[0.46315598 0.46610996]\n",
      "  [0.44625235 0.40906793]\n",
      "  [0.49124503 0.5177178 ]\n",
      "  [0.7843791  0.50921166]\n",
      "  [0.5284072  0.74829274]\n",
      "  [0.6018791  0.49288306]\n",
      "  [0.58284706 0.58028543]]\n",
      "\n",
      " [[0.6135956  0.6257918 ]\n",
      "  [0.58306056 0.5955361 ]\n",
      "  [0.4666657  0.57663584]\n",
      "  [0.40532956 0.44579044]\n",
      "  [0.48135078 0.41724458]\n",
      "  [0.43076423 0.43968916]\n",
      "  [0.51629466 0.5360454 ]]\n",
      "\n",
      " [[0.43288702 0.37168756]\n",
      "  [0.34883335 0.35799962]\n",
      "  [0.4070672  0.39506528]\n",
      "  [0.4909677  0.28010106]\n",
      "  [0.23342212 0.42038238]\n",
      "  [0.5146557  0.455518  ]\n",
      "  [0.49173164 0.5082905 ]]\n",
      "\n",
      " [[0.409333   0.38036084]\n",
      "  [0.46822238 0.3900844 ]\n",
      "  [0.45746064 0.370625  ]\n",
      "  [0.40499035 0.48350275]\n",
      "  [0.57411295 0.41062516]\n",
      "  [0.32342136 0.45428246]\n",
      "  [0.3501444  0.38028917]]\n",
      "\n",
      " [[0.29254687 0.4131273 ]\n",
      "  [0.36980408 0.31552643]\n",
      "  [0.34568724 0.39851376]\n",
      "  [0.4141134  0.4216095 ]\n",
      "  [0.42535645 0.45240062]\n",
      "  [0.5035978  0.4054047 ]\n",
      "  [0.3348803  0.46708572]]]\n",
      "None\n",
      "Square x square: [[[3.8863502e-02 3.7174445e-01]\n",
      "  [2.4360454e+00 2.0678878e+00]\n",
      "  [5.9409528e+00 6.1928973e+00]\n",
      "  [1.2018809e+01 1.1941865e+01]\n",
      "  [2.0098305e+01 1.9592505e+01]\n",
      "  [2.8359777e+01 3.0747110e+01]\n",
      "  [4.0165432e+01 4.4176369e+01]]\n",
      "\n",
      " [[4.6850261e-01 4.0626742e-02]\n",
      "  [1.6221271e+00 2.3848863e+00]\n",
      "  [5.1745200e+00 6.7906938e+00]\n",
      "  [1.2840833e+01 1.1096326e+01]\n",
      "  [1.9678078e+01 1.8429956e+01]\n",
      "  [3.0220911e+01 2.7162134e+01]\n",
      "  [4.0352730e+01 4.5265789e+01]]\n",
      "\n",
      " [[4.9176922e-01 3.4062549e-02]\n",
      "  [2.3155119e+00 1.7639692e+00]\n",
      "  [6.1154723e+00 6.5773921e+00]\n",
      "  [1.3861363e+01 1.2736090e+01]\n",
      "  [1.9412018e+01 1.8337538e+01]\n",
      "  [3.1175413e+01 2.8403704e+01]\n",
      "  [4.1075054e+01 4.5117172e+01]]\n",
      "\n",
      " [[3.5956010e-02 4.2621613e-01]\n",
      "  [1.9226573e+00 2.4876876e+00]\n",
      "  [6.3913307e+00 5.7018118e+00]\n",
      "  [1.4058529e+01 1.5594922e+01]\n",
      "  [1.7041744e+01 1.8679535e+01]\n",
      "  [2.9314226e+01 2.9266665e+01]\n",
      "  [4.1731926e+01 4.6086605e+01]]\n",
      "\n",
      " [[2.7723312e-02 3.9393753e-01]\n",
      "  [2.5588667e+00 1.6909679e+00]\n",
      "  [6.1865067e+00 5.4528356e+00]\n",
      "  [1.2671749e+01 1.4089781e+01]\n",
      "  [1.8753355e+01 1.9400961e+01]\n",
      "  [3.1016626e+01 2.9561003e+01]\n",
      "  [4.6292416e+01 4.1108849e+01]]\n",
      "\n",
      " [[3.7103944e-02 3.8558340e-01]\n",
      "  [2.5697896e+00 1.5711944e+00]\n",
      "  [6.2916994e+00 5.6656513e+00]\n",
      "  [1.1850971e+01 1.2992777e+01]\n",
      "  [1.9628967e+01 1.9073347e+01]\n",
      "  [2.7562454e+01 3.0509241e+01]\n",
      "  [4.5263271e+01 4.0735615e+01]]\n",
      "\n",
      " [[4.6923295e-02 4.0546852e-01]\n",
      "  [2.2340796e+00 1.3435676e+00]\n",
      "  [6.5814271e+00 5.0580645e+00]\n",
      "  [1.0831853e+01 1.2112335e+01]\n",
      "  [1.7846857e+01 2.0620451e+01]\n",
      "  [2.6883518e+01 2.9692316e+01]\n",
      "  [4.2770920e+01 4.1730228e+01]]]\n",
      "DIvide by cell size [[[0.02816261 0.08710121]\n",
      "  [0.22296908 0.20543075]\n",
      "  [0.348201   0.3555076 ]\n",
      "  [0.49525934 0.49367148]\n",
      "  [0.64044476 0.6323346 ]\n",
      "  [0.76076996 0.79214394]\n",
      "  [0.90537435 0.9495044 ]]\n",
      "\n",
      " [[0.09778178 0.02879439]\n",
      "  [0.18194678 0.22061539]\n",
      "  [0.3249653  0.37227085]\n",
      "  [0.5119158  0.47587353]\n",
      "  [0.633714   0.6132875 ]\n",
      "  [0.78533643 0.74453294]\n",
      "  [0.9074828  0.96114075]]\n",
      "\n",
      " [[0.10018037 0.02636577]\n",
      "  [0.21738294 0.18973501]\n",
      "  [0.3532783  0.36637753]\n",
      "  [0.5318693  0.5098237 ]\n",
      "  [0.62941533 0.61174786]\n",
      "  [0.7976421  0.7613589 ]\n",
      "  [0.9155689  0.9595617 ]]\n",
      "\n",
      " [[0.02708867 0.09326462]\n",
      "  [0.19808559 0.22532007]\n",
      "  [0.3611583  0.34112096]\n",
      "  [0.53563863 0.56414866]\n",
      "  [0.58973783 0.6174261 ]\n",
      "  [0.77346593 0.7728382 ]\n",
      "  [0.92286074 0.9698159 ]]\n",
      "\n",
      " [[0.02378617 0.08966349]\n",
      "  [0.22852084 0.18576746]\n",
      "  [0.35532412 0.3335901 ]\n",
      "  [0.5085343  0.53623366]\n",
      "  [0.6186449  0.62923604]\n",
      "  [0.79560816 0.77671474]\n",
      "  [0.971979   0.9159455 ]]\n",
      "\n",
      " [[0.02751769 0.08870766]\n",
      "  [0.22900805 0.17906757]\n",
      "  [0.3583323  0.34003755]\n",
      "  [0.49178913 0.5149356 ]\n",
      "  [0.6329227  0.6239006 ]\n",
      "  [0.7499994  0.7890739 ]\n",
      "  [0.96111405 0.911778  ]]\n",
      "\n",
      " [[0.03094541 0.0909663 ]\n",
      "  [0.21352625 0.1655891 ]\n",
      "  [0.3664899  0.32128772]\n",
      "  [0.4701683  0.49718258]\n",
      "  [0.6035077  0.64871067]\n",
      "  [0.74070454 0.778438  ]\n",
      "  [0.9342783  0.92284197]]]\n",
      "Normalized box\n",
      "box * image_size\n",
      "[[ 12.61685   39.021343]\n",
      " [ 99.89015   92.032974]\n",
      " [155.99405  159.26741 ]\n",
      " [221.87619  221.16483 ]\n",
      " [286.91925  283.2859  ]\n",
      " [340.82495  354.8805  ]\n",
      " [405.6077   425.37796 ]]\n",
      "\n",
      "Set Prob of class [[[ 8.61836270e-06  4.29605706e-07  8.93204628e-07  9.95882132e-08\n",
      "    1.53337237e-06  3.02000558e-07  1.05912989e-06 -9.79259909e-08\n",
      "    2.70242424e-08  3.02930516e-07 -1.38751176e-07 -4.31684413e-07\n",
      "    2.54950550e-07  1.47851466e-07  6.77130856e-07  2.50321932e-06\n",
      "   -8.74357795e-08  1.19332867e-07 -5.44680034e-08  6.91278728e-07]\n",
      "  [ 2.54212553e-03 -3.35275545e-05 -2.70698620e-05  2.31957092e-04\n",
      "    4.47190017e-04  2.01425391e-05  8.75143378e-05  1.07943320e-04\n",
      "   -9.88595502e-07  7.89260957e-05  9.47704975e-05  2.63856073e-05\n",
      "    1.01521699e-04  4.47372349e-06  1.46699545e-04  4.51721164e-04\n",
      "   -3.73697105e-07  7.82429852e-05  7.12930978e-06  2.60112811e-05]\n",
      "  [ 5.37228363e-04 -4.47729462e-06  5.45584262e-05 -1.80624261e-06\n",
      "    1.02326303e-04  2.36453525e-06  1.23693990e-05 -3.07208284e-05\n",
      "    3.07309783e-05  1.14728573e-06 -1.90179378e-06 -1.54554050e-06\n",
      "   -4.60293631e-06  2.91847300e-05  1.80357201e-05  7.45483048e-05\n",
      "    1.42410818e-05 -1.27288022e-05  1.09710918e-05 -2.20910351e-05]\n",
      "  [ 5.23314951e-03  8.04046940e-05  5.40530484e-04  5.90192685e-05\n",
      "    8.80135514e-04 -5.67821662e-05 -3.07492126e-04 -1.93985412e-04\n",
      "    2.48868106e-04  3.16015473e-07  1.74102934e-06  1.44928345e-04\n",
      "    4.02909528e-08 -4.57584538e-05  1.03762955e-04  8.81636457e-04\n",
      "    1.10456858e-04  2.99432486e-05  8.62232173e-06 -6.48288769e-05]\n",
      "  [ 5.26984979e-04 -9.47226272e-06  5.30864927e-05 -4.08635378e-06\n",
      "    8.19174529e-05 -2.47646108e-06 -4.66553047e-06 -6.66138840e-06\n",
      "   -3.58766338e-05 -8.98295730e-06  3.32049422e-06  1.17414265e-05\n",
      "    2.99876524e-06  1.53235007e-07  2.38809171e-05  7.98561014e-05\n",
      "    4.60409183e-06  1.01444266e-05 -1.13880878e-06 -4.30502041e-06]\n",
      "  [ 1.58162566e-03 -5.78994877e-06  4.46615741e-05  1.47526865e-04\n",
      "    3.26245150e-04  1.48929066e-05  2.77738059e-06 -5.77836981e-05\n",
      "    6.20647261e-05  1.22094289e-05 -4.09053901e-05 -1.15913072e-05\n",
      "    3.38583995e-05  5.47092422e-05  6.66141132e-05  3.27390298e-04\n",
      "    7.18408119e-05 -7.40505420e-05 -8.82461791e-06 -3.74054725e-05]\n",
      "  [ 1.15287211e-03  2.07232588e-05  7.33060660e-05  2.10744693e-05\n",
      "    2.19401292e-04  1.01208834e-05  8.17140681e-05  5.88862895e-05\n",
      "   -1.45777676e-05  3.21575044e-07  3.92703732e-05  6.68735083e-05\n",
      "   -3.36149205e-05  2.88977571e-05  1.32344867e-04  3.18732811e-04\n",
      "    1.94030072e-05 -2.99906933e-05  4.94510823e-05  6.45638720e-05]]\n",
      "\n",
      " [[ 1.79023284e-03  1.18624912e-05  4.09752247e-05  1.33534384e-04\n",
      "    3.25206318e-04  1.38151387e-04  2.46121067e-06  5.28822493e-05\n",
      "    5.82976572e-05 -2.39252167e-05 -2.93022495e-05  9.22800791e-06\n",
      "   -1.26924842e-05  1.20393350e-04  1.88129416e-04  4.46348509e-04\n",
      "   -5.53492755e-05  3.06565744e-05  4.95435961e-05  1.16280244e-04]\n",
      "  [ 4.07159841e-03  1.56236310e-05  1.30308719e-04 -1.19816123e-05\n",
      "    4.60341689e-04  4.21668447e-05  5.29676036e-05 -1.35013790e-04\n",
      "   -1.30682010e-05 -8.33104423e-06  8.65079201e-05 -1.11558395e-04\n",
      "   -4.89189506e-06  1.11664755e-04  2.50311597e-04  7.24363083e-04\n",
      "    3.74535484e-05  9.01477506e-06 -1.15602073e-04 -2.09355261e-04]\n",
      "  [ 9.57453717e-03 -2.26632794e-04 -1.43608804e-05  2.05752222e-04\n",
      "    1.60969736e-03 -2.93634657e-04  2.95182719e-04 -3.53775511e-04\n",
      "   -3.31112795e-04 -1.54566369e-04  7.70557235e-05 -2.78846681e-04\n",
      "    1.79598264e-05  2.65813524e-05  2.37136293e-04  1.09783269e-03\n",
      "   -9.84188882e-05  4.67445680e-05  1.54937763e-04 -1.28892119e-04]\n",
      "  [ 7.12579757e-04 -4.62899079e-05  1.42452318e-05  1.38577582e-06\n",
      "    1.14626295e-04 -6.05615332e-06 -3.06800284e-05 -2.24772884e-05\n",
      "   -2.51115284e-06 -3.88832559e-05  1.40008287e-05 -3.69105619e-05\n",
      "    5.39280018e-06  2.97330971e-05 -5.78561776e-06  6.09654853e-05\n",
      "   -4.73713817e-06  1.84162727e-05  1.64546800e-05  1.14849900e-05]\n",
      "  [-1.71411433e-03 -6.57801866e-05  1.83456780e-06  6.17859723e-06\n",
      "   -1.95366156e-04 -3.47067253e-05  5.46170268e-05  7.06287683e-05\n",
      "    7.24738993e-06 -2.24739706e-05 -3.15174584e-05  4.46571394e-05\n",
      "   -9.77638319e-06 -1.59834581e-05  5.91967691e-05 -1.54445326e-04\n",
      "   -1.42083636e-05 -3.66059903e-05 -4.81443858e-05 -3.85402382e-06]\n",
      "  [ 1.42351049e-03 -2.23055904e-05  1.20245468e-05  9.96245035e-07\n",
      "    1.79141236e-04 -5.66729705e-06 -9.36759898e-06  1.39040112e-05\n",
      "   -6.15286990e-05 -3.34708093e-05 -1.02722961e-05 -3.08195158e-05\n",
      "    2.11088991e-05 -2.76561477e-05  9.80667610e-05  1.20518649e-04\n",
      "    3.23623112e-06  4.07244297e-05  1.35954933e-05  7.88327043e-07]\n",
      "  [ 2.99679092e-03 -6.23270680e-05  1.29004611e-05  1.64236553e-04\n",
      "    4.93114057e-04 -5.31377773e-05 -1.09873872e-04 -3.83241349e-05\n",
      "    1.19245029e-04  8.37286098e-06 -7.57558664e-05 -9.07738558e-06\n",
      "    9.72405032e-05 -6.21745785e-05  2.79584667e-04  6.28268986e-04\n",
      "    1.07855085e-04  7.50290128e-05 -3.01230593e-05  3.59970581e-05]]\n",
      "\n",
      " [[-1.17640232e-03  3.49172042e-05 -2.19074682e-05 -2.92343384e-06\n",
      "   -1.75257403e-04 -1.11827067e-05 -6.39929858e-05 -7.38436893e-06\n",
      "    2.28276185e-05  3.85296044e-05 -2.27273122e-05  9.45209467e-06\n",
      "   -2.07499961e-05 -9.12739506e-06 -8.69026189e-05 -1.62886019e-04\n",
      "    5.33259163e-06  1.41377395e-05 -5.34661849e-05  1.64038465e-05]\n",
      "  [ 1.78728648e-03 -1.81191608e-05  2.73827172e-05  1.47921983e-05\n",
      "    2.52448925e-04 -3.51689159e-05  1.67640555e-05 -1.89708553e-05\n",
      "   -1.36882109e-05 -4.44528450e-06 -3.27440175e-05 -6.67200993e-06\n",
      "    8.42776790e-05  1.72644432e-05  7.62902127e-05  3.02753266e-04\n",
      "   -2.73737078e-05  1.84121818e-05  6.00864551e-05 -6.33700765e-05]\n",
      "  [-8.24640878e-03  5.55462939e-05  1.29556111e-06  6.69601723e-05\n",
      "   -1.25655020e-03  4.41835815e-04  9.68986787e-05  1.78661328e-04\n",
      "   -2.94440761e-05 -3.04384739e-05 -1.04483690e-04 -7.16865761e-05\n",
      "    5.45736248e-06  3.46327055e-04 -5.53819875e-04 -6.48045447e-04\n",
      "   -1.65685371e-04  7.97342218e-05 -4.80665549e-05 -2.35441831e-07]\n",
      "  [-4.63984627e-03  4.07989719e-05  2.85476563e-05  6.08080809e-05\n",
      "   -5.30371850e-04  5.93119912e-05  1.43441110e-04  1.01543010e-04\n",
      "    8.32509031e-05  1.02566388e-04 -9.37117511e-05  8.61658627e-05\n",
      "    9.87477470e-05  2.41264541e-04 -2.90659140e-04 -1.96463501e-04\n",
      "    4.45288206e-05  5.12001816e-06 -5.51447738e-05 -1.78186499e-04]\n",
      "  [-2.51365881e-02  1.47982224e-04  2.14906526e-04 -3.98117700e-04\n",
      "   -3.27661936e-03  3.89821915e-04  1.04466418e-03 -4.44356061e-04\n",
      "    7.97280984e-04  7.49393512e-05 -4.64938697e-04  5.95694059e-04\n",
      "    4.86241392e-04  1.46317168e-03 -1.56755932e-03 -8.17955530e-04\n",
      "   -5.33129263e-04 -2.57706823e-04 -2.38385473e-04 -4.16415540e-04]\n",
      "  [ 2.32397602e-03  5.26114454e-05  4.84379816e-05 -1.14307977e-05\n",
      "    1.85923273e-04 -2.70550699e-05 -6.18215126e-05 -2.12197174e-05\n",
      "    6.01164575e-05  7.88425677e-06  6.61469530e-05 -4.08100750e-05\n",
      "   -5.48808057e-05 -9.85370716e-05  1.34538146e-04  1.46752966e-04\n",
      "    4.73777691e-05 -3.42607636e-05  6.07302682e-05 -8.73478893e-06]\n",
      "  [ 2.24993471e-03 -7.05722232e-06 -1.93247888e-05 -7.84628064e-05\n",
      "    2.52943864e-04  8.58586718e-05  2.23932744e-04 -6.82495283e-06\n",
      "    6.37579651e-05 -5.74530204e-05  4.90576931e-05  6.11039013e-06\n",
      "    7.29635358e-05  3.84094565e-05  3.04908870e-04  2.38128079e-04\n",
      "    4.52198547e-05 -4.43553790e-06  6.78371589e-06  6.26703695e-05]]\n",
      "\n",
      " [[-3.08345328e-03  1.07475362e-05  7.18735237e-06 -1.09369466e-05\n",
      "   -4.76568355e-04 -6.14250848e-06 -6.37141231e-04  6.19490384e-05\n",
      "   -1.50095788e-04  1.04172424e-04 -1.49348110e-04  9.42723091e-06\n",
      "    7.19261297e-05  2.97710776e-05 -7.40785908e-04 -2.93329678e-04\n",
      "   -8.37810949e-05 -1.35236362e-04 -1.97416026e-04  2.58344429e-04]\n",
      "  [-2.48805042e-02 -5.45718533e-04  2.68917705e-04  1.37527159e-03\n",
      "   -2.43970053e-03  9.13273368e-04 -1.06798019e-03  5.91337215e-04\n",
      "   -1.54606430e-04  7.27618972e-05 -1.14079274e-03  9.86362342e-04\n",
      "   -1.64476887e-03  2.57663458e-04 -4.61428100e-03 -2.17103120e-03\n",
      "    9.30022507e-05 -1.88273480e-04 -1.47907808e-03  9.71014670e-04]\n",
      "  [-1.96545981e-02 -3.32305463e-05 -1.11649941e-04  1.13899878e-04\n",
      "   -2.54341983e-03  1.02610770e-03  5.26574790e-04  5.20851230e-04\n",
      "   -1.40941981e-03  2.46631651e-04  3.79880541e-04  4.44941252e-04\n",
      "   -1.13935652e-03  9.75726405e-04 -2.54946528e-03 -1.23635109e-03\n",
      "    3.48963804e-04  4.83078155e-04 -1.16822914e-04  6.47188863e-04]\n",
      "  [ 4.00242627e-01 -3.34795727e-03 -7.65543338e-03 -3.87743604e-03\n",
      "    2.60550268e-02 -1.14444504e-02  2.12731794e-03 -6.05551805e-03\n",
      "    1.02326442e-02 -3.44313588e-03 -5.30384108e-03 -5.54300891e-03\n",
      "    2.05254112e-03 -1.69831701e-02 -5.05732745e-03  1.17962444e-02\n",
      "    1.05996931e-03  2.56042415e-03 -8.16494972e-03  5.58413193e-03]\n",
      "  [ 2.92804521e-02  2.61556008e-04 -1.14752047e-05 -6.25021232e-04\n",
      "    1.25815126e-03 -6.64883933e-04  2.53865030e-04 -2.74517894e-04\n",
      "    3.13158787e-04 -3.59880563e-04  1.85366356e-04 -1.47144077e-04\n",
      "    4.06985724e-04 -2.02795971e-04 -4.36143193e-04  7.83225580e-04\n",
      "    4.62180498e-04  6.64433537e-05  3.06075730e-04  1.05459432e-04]\n",
      "  [-5.54789847e-04  6.01302054e-06  1.43619682e-05  1.26652203e-05\n",
      "   -5.01504364e-05  1.58609819e-05 -2.33748196e-05 -3.40107408e-06\n",
      "   -9.34060517e-06  6.00200747e-06  2.37887275e-06  8.44945362e-07\n",
      "   -1.55019097e-05  9.22717447e-07 -6.46901171e-05 -9.57235898e-06\n",
      "   -6.29087754e-06  3.33400476e-06 -5.98687757e-06  7.79217953e-06]\n",
      "  [-5.85967209e-04  1.81202631e-06 -1.98454672e-05 -1.51818756e-06\n",
      "   -5.91898061e-05 -2.25335007e-05 -7.27241422e-05  8.75664045e-06\n",
      "   -1.95038429e-05 -7.04920012e-06 -5.49047536e-06 -9.28903410e-06\n",
      "   -2.35465068e-05  7.00680630e-06 -7.01873651e-05 -1.98670969e-05\n",
      "   -2.12826471e-05  1.12178577e-05 -3.23393397e-05  6.83388907e-06]]\n",
      "\n",
      " [[ 3.85535043e-03 -3.79881007e-04 -1.32434609e-04 -2.03533666e-04\n",
      "    8.24582006e-04 -2.21197115e-04  1.14140508e-03 -1.27646548e-04\n",
      "    5.99686522e-04 -1.97410045e-05  6.58171630e-05 -4.22276789e-04\n",
      "    2.29137702e-04 -2.07637040e-05  1.75348180e-03  5.24978561e-04\n",
      "    1.42745121e-04  5.88204748e-05 -1.69154810e-05 -3.82740312e-04]\n",
      "  [ 4.13029501e-03 -4.73834545e-04 -5.42389207e-05 -2.17563094e-04\n",
      "    3.67779547e-04 -6.95965573e-05  7.13179645e-04 -1.91151266e-04\n",
      "    4.84527205e-04 -6.28813723e-05  2.81601941e-04 -1.10472589e-04\n",
      "    7.10296881e-05  4.80873132e-05  2.02218234e-03  3.52406088e-04\n",
      "    1.23018239e-04  2.56181920e-05  7.35618669e-05 -4.92430263e-05]\n",
      "  [ 2.89632566e-02 -1.67604198e-03 -8.26803793e-04 -1.07758527e-03\n",
      "    2.53051915e-03 -1.17261149e-03  3.75842676e-03 -2.02813535e-03\n",
      "    4.60035773e-03 -1.65813253e-03  4.21206350e-04 -4.40003438e-04\n",
      "    1.70708983e-04  3.63616738e-04  1.06867095e-02  9.82090598e-04\n",
      "    4.42734512e-04 -7.08533393e-04 -1.03855785e-03 -1.21600728e-03]\n",
      "  [-1.95961334e-02  6.49516354e-04  3.55840777e-04  9.04040469e-04\n",
      "   -6.04506466e-04  1.19654438e-03 -1.60653132e-03  7.07149040e-04\n",
      "   -1.95838348e-03  7.58126494e-04 -1.18005241e-03  5.74462698e-04\n",
      "    8.95659832e-05 -5.66645642e-04 -1.18678948e-03 -1.13014353e-03\n",
      "   -4.09185857e-04  3.18913844e-05  5.24540723e-04  4.46831837e-04]\n",
      "  [-2.45433506e-02  6.83655206e-04  7.91808183e-04  7.00613949e-04\n",
      "   -1.23816577e-03  9.65445419e-04 -2.28681415e-03  1.31906534e-03\n",
      "   -9.02036671e-04  2.57399050e-04 -2.04510801e-03 -1.69431994e-04\n",
      "    2.63575232e-04 -2.01930944e-03 -1.18367001e-03 -1.91743730e-03\n",
      "   -3.22189182e-04  2.15131586e-04  2.34566192e-04  3.80406636e-05]\n",
      "  [-4.86237375e-04  2.95848167e-05  2.58407708e-05  2.14556730e-05\n",
      "   -5.54853177e-05  1.02952754e-05 -6.14895689e-05  2.38339489e-05\n",
      "   -9.38486119e-05 -9.18185287e-06 -6.79186996e-07 -1.12218486e-05\n",
      "   -2.48261385e-05 -4.01985708e-05 -1.18383490e-04 -1.99086862e-05\n",
      "   -1.41596479e-06  2.28116678e-05  1.16988872e-06  1.77963193e-05]\n",
      "  [-4.26055724e-03  4.03018872e-04 -1.35872091e-04  1.64743775e-04\n",
      "   -3.15622165e-04  1.66300408e-04 -9.50518181e-04  2.20520524e-04\n",
      "   -9.20694787e-04  1.25119870e-04  4.88158912e-05 -8.31428697e-05\n",
      "   -3.24917695e-04 -1.05707470e-04 -1.19005179e-03 -4.73062333e-04\n",
      "   -2.16804750e-04  2.47498683e-04 -1.47556479e-04  2.36240667e-04]]\n",
      "\n",
      " [[-1.19371349e-02 -5.51522360e-04  1.42553195e-04 -7.87581666e-04\n",
      "   -2.75903428e-03 -6.55495824e-05 -7.29873031e-03  1.75027759e-04\n",
      "   -6.27865037e-03  9.15074546e-04  7.72524800e-04  2.43807503e-04\n",
      "   -1.70524392e-04 -3.24771070e-04 -6.16223831e-03 -1.83018844e-03\n",
      "    6.23121625e-04 -8.46152194e-04  3.85274179e-04  1.22586731e-04]\n",
      "  [-4.36002109e-03  3.57923273e-04  3.32488358e-04  4.83844015e-05\n",
      "   -3.94251663e-04 -1.31157358e-04 -1.86612189e-03  1.35091657e-04\n",
      "   -1.53632101e-03  8.17217297e-05 -2.52365920e-04  1.08221619e-04\n",
      "   -2.61214387e-04 -2.68286065e-04 -1.74027833e-03 -5.86958369e-04\n",
      "    1.79787763e-04 -1.13341041e-04  2.83118396e-04  6.17817568e-05]\n",
      "  [-2.20140466e-03  1.87371232e-04 -1.73490407e-05  8.79922081e-05\n",
      "   -3.37225210e-04  4.68032595e-05 -5.02695271e-04  1.83649841e-04\n",
      "   -7.27625447e-04  9.11812895e-05 -1.63948614e-04 -4.67664249e-05\n",
      "   -1.19504446e-04 -1.84251941e-04 -2.32242193e-04 -1.42690318e-04\n",
      "   -7.42930788e-05  5.45251642e-05  8.51439036e-05  1.09577049e-04]\n",
      "  [ 3.88181442e-03 -3.14182136e-04  5.81838067e-05 -1.29194726e-04\n",
      "    5.05627948e-04 -6.83002218e-05  8.63085501e-04 -1.78876871e-04\n",
      "    5.66630799e-04 -1.20892248e-04  8.18333763e-04  6.60897422e-05\n",
      "    2.06565005e-06  1.69174265e-04  2.72077305e-04  1.20041135e-04\n",
      "    2.05789533e-04 -2.11351915e-04 -2.81486660e-04  1.93085452e-05]\n",
      "  [-1.25000002e-02  1.24951184e-03 -1.92003390e-05  2.82880501e-04\n",
      "   -2.13408843e-03  8.23945389e-04 -3.25147528e-03  5.24541130e-04\n",
      "   -2.65360577e-03  1.92474472e-04 -1.29710836e-03 -1.20924640e-04\n",
      "   -9.29289381e-04 -7.35023001e-04 -3.25061381e-03 -1.65568280e-03\n",
      "   -5.07263117e-04  8.76571139e-05  1.08642667e-03  1.80190415e-04]\n",
      "  [-2.59992410e-03  3.98972858e-04  4.30483524e-05  1.68361570e-04\n",
      "   -2.76567880e-04  9.81531193e-05 -9.36126627e-04 -5.86045826e-05\n",
      "   -1.00173964e-03  1.56612659e-05 -1.44159101e-04  2.26969405e-05\n",
      "    1.74294881e-04 -1.37947514e-04 -8.45398521e-04 -2.64862843e-04\n",
      "   -1.38420248e-04  1.77657712e-04 -6.29175411e-05  1.17481635e-04]\n",
      "  [-5.34854305e-04  6.35993056e-05 -2.46731906e-05 -5.88585090e-06\n",
      "   -4.24825485e-05  4.96262983e-05 -4.20043041e-04 -7.61969204e-06\n",
      "   -2.90325377e-04  1.20291406e-05 -2.77587078e-05  1.99265469e-05\n",
      "    2.38390430e-06  9.56701933e-06 -2.31946644e-04 -4.37550807e-05\n",
      "   -7.29450767e-05 -8.99526731e-06  1.27335024e-05  5.10318605e-05]]\n",
      "\n",
      " [[-1.39172084e-03 -2.15460066e-04 -2.05778284e-04 -3.78175464e-04\n",
      "   -4.13573842e-04 -3.14208824e-04 -1.71592121e-03 -3.03538527e-05\n",
      "   -7.90610677e-04 -1.25420338e-04 -6.42104496e-05  9.46398213e-05\n",
      "   -8.47248521e-05  1.37871059e-04 -6.85200968e-04 -1.05360814e-04\n",
      "   -1.52824985e-04  3.30896401e-05 -2.37021159e-04  5.24280222e-05]\n",
      "  [ 3.47764639e-04  1.95148823e-06  1.32197538e-05  1.25289889e-05\n",
      "    8.98175713e-05 -8.49840580e-06  2.42828988e-04  2.23982988e-05\n",
      "    9.64652791e-05 -2.00102863e-06  4.70014839e-07 -2.87437288e-05\n",
      "    1.42384788e-05  7.61548199e-06  5.65057890e-05  2.49338063e-05\n",
      "    1.73115714e-05  1.86471789e-06  1.33213525e-05  1.25641864e-05]\n",
      "  [-4.39816940e-04  1.93663091e-05  4.19635484e-07  2.28435892e-05\n",
      "   -1.00920122e-04 -5.96034261e-06 -1.68362385e-04  6.30623208e-06\n",
      "   -1.26050785e-04  4.53456067e-07 -8.82877976e-06  1.23871778e-05\n",
      "    1.47329147e-05 -3.02193712e-05 -4.13882117e-05 -2.38428311e-05\n",
      "   -1.15979374e-05 -1.27157637e-05 -1.98097410e-07  3.34369020e-06]\n",
      "  [ 1.80281419e-03 -1.07862106e-04  4.73074506e-05  8.25562020e-05\n",
      "    1.08437824e-04  3.37430993e-06  4.98695648e-04  7.42004559e-05\n",
      "    4.23252495e-04 -4.23873553e-06  4.59829229e-04  8.55369726e-05\n",
      "    8.99845545e-05  9.88678148e-05  3.17662401e-04  1.10072870e-04\n",
      "    2.51362439e-06  5.96412065e-05 -6.51742448e-05 -8.74180405e-05]\n",
      "  [ 6.28702855e-03 -4.05923871e-04  3.12714437e-05  5.15694672e-04\n",
      "    9.80745186e-04 -8.69611758e-05  2.98680319e-03  2.17707595e-04\n",
      "    1.28289510e-03 -8.42878362e-04  1.09805784e-03  3.00828164e-04\n",
      "    2.95524951e-04 -1.56739261e-04  1.46049948e-03  8.27384763e-04\n",
      "   -1.08515625e-04  2.41442060e-04  1.07545035e-04 -3.66493245e-04]\n",
      "  [ 2.36481079e-03 -1.14838200e-04  1.79567069e-04  7.69843900e-05\n",
      "    4.77543974e-04  2.17015895e-05  1.31499546e-03  7.46758815e-05\n",
      "    6.04323810e-04 -9.61297410e-05  1.86271791e-04  2.19127978e-05\n",
      "    8.83467583e-05  3.46219822e-05  4.35144902e-04  3.13655066e-04\n",
      "   -2.92322966e-05  3.99540695e-05 -3.93046321e-05 -9.46902437e-05]\n",
      "  [ 2.15882645e-03 -1.16764844e-04  1.04369952e-04  7.30361426e-05\n",
      "    5.15452062e-04  1.86737801e-04  2.41261907e-03  7.41478361e-05\n",
      "    7.68334372e-04 -5.38028416e-07  7.88727732e-07  7.60754517e-07\n",
      "    2.06783254e-04  1.50596723e-04  8.43064860e-04  3.09105410e-04\n",
      "    2.44736671e-04  8.16272877e-05  1.74832036e-04  2.96719627e-05]]]\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Filter Mat probs :   (7, 7, 2, 20)\n",
      "Filter Mat probs :   [[[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]]\n",
      "------------------------------\n",
      "Match Boxes [[[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]\n",
      "\n",
      "\n",
      " [[[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]\n",
      "\n",
      "  [[False False False ... False False False]\n",
      "   [False False False ... False False False]]]]\n",
      "------------------------------\n",
      "Non Zero Filtered mat box (array([3, 3]), array([3, 4]), array([1, 0]), array([0, 0]))\n",
      "Non Zero Filtered mat box [3 3]\n",
      "box filtered (2, 4)\n",
      "[[252.7386  220.5306  328.10657 132.05702]\n",
      " [264.20255 222.80646 312.01578 124.72816]]\n",
      "prob filtered\n",
      "[0.40024263 0.55540818]\n",
      "classes num filtered [0 0]\n",
      "Arg sort probs filtered  [1 0]\n",
      "Boxes filtered  [[264.20255 222.80646 312.01578 124.72816]\n",
      " [252.7386  220.5306  328.10657 132.05702]]\n",
      "prob filtered [0.55540818 0.40024263]\n",
      "class num filter [0 0]\n"
     ]
    }
   ],
   "source": [
    "detector = Detector(yolo, weight_file)\n",
    "\n",
    "imname = 'test/jhaaz.jpeg'\n",
    "detector.image_detector(imname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.array(\n",
    "    [np.arange(7)] * 7 * 2)\n",
    "offset = np.transpose(\n",
    "    np.reshape(\n",
    "        offset,\n",
    "        [2, 7 ,7]),\n",
    "    (1, 2, 0))\n",
    "print(offset.shape)\n",
    "print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_trans=np.transpose(offset,(1,0, 2))\n",
    "print(offset.shape)\n",
    "print(offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
